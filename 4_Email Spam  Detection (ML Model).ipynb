{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88037ac1",
   "metadata": {},
   "source": [
    "# Treue Technologies (Internship - Data Science) [Ansh Pandey]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a453b",
   "metadata": {},
   "source": [
    "##  Task 4 : Email Spam Detection (ML Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a770319",
   "metadata": {},
   "source": [
    "### Objective = Create an email spam detection system that uses machine learning algorithms to classify incoming emails. By training the model on a labeled dataset of \"SPAM\" and \"NON-SPAM\" emails, We aim to develop an accurate and efficient spam detector that can reliably identify and categorize emails based on their content and characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4d96b",
   "metadata": {},
   "source": [
    "#### i) Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a8c391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8aadcc",
   "metadata": {},
   "source": [
    "#### ii) Loading The Dataset (.csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d2653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science or Analytics_Ansh\\\\Tasks Images\\spam.csv', encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ec525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        v1                                                 v2 Unnamed: 2  \\\n",
      "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "...    ...                                                ...        ...   \n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
      "5568   ham              Will ÃŒ_ b going to esplanade fr home?        NaN   \n",
      "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
      "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
      "5571   ham                         Rofl. Its true to its name        NaN   \n",
      "\n",
      "     Unnamed: 3 Unnamed: 4  \n",
      "0           NaN        NaN  \n",
      "1           NaN        NaN  \n",
      "2           NaN        NaN  \n",
      "3           NaN        NaN  \n",
      "4           NaN        NaN  \n",
      "...         ...        ...  \n",
      "5567        NaN        NaN  \n",
      "5568        NaN        NaN  \n",
      "5569        NaN        NaN  \n",
      "5570        NaN        NaN  \n",
      "5571        NaN        NaN  \n",
      "\n",
      "[5572 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e310c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d708ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32e12be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e5a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1            object\n",
      "v2            object\n",
      "Unnamed: 2    object\n",
      "Unnamed: 3    object\n",
      "Unnamed: 4    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b4d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords dataset if you haven't already (Becuse I haven't)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2b14d",
   "metadata": {},
   "source": [
    "#### iii) Preprocessing The Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a1f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and tokenize\n",
    "    text = nltk.word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    # Join tokens back into a single string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['v2'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488faef9",
   "metadata": {},
   "source": [
    "#### iv) Splitting The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6718ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned_text']\n",
    "Y = data['v1']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48e50f",
   "metadata": {},
   "source": [
    "#### v) Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf01826",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ecf41",
   "metadata": {},
   "source": [
    "#### vi) Building And Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47838360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70487f8e",
   "metadata": {},
   "source": [
    "#### vii) Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad985433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9650224215246637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       949\n",
      "        spam       1.00      0.77      0.87       166\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "\n",
    "print(f'Accuracy : {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603249d",
   "metadata": {},
   "source": [
    "# Done (Save and Deploy this ML Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80245636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email_spam_detection_model.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "\n",
    "# Save the model\n",
    "model_filename = \"email_spam_detection_model.joblib\"\n",
    "dump(model, model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed0974e",
   "metadata": {},
   "source": [
    "#### Using CountVectorizer to train the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1039fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63da8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing my Data\n",
    "texts = [\"This is a sample email.\", \"Get rich quick! Earn $$$ in just one week!\", \"Hi, how are you? Let's meet up this weekend.\", \"Buy now! Limited time offer!\", \"You've won a free iPhone. Claim your prize now!\", \"Important meeting tomorrow at 10 AM.\", \"Congratulations, you've won a lottery!\", \"Meet singles in your area! Chat now!\", \"Please find attached the report for review.\", \"Make $$$ from home with our work-at-home program\", \"Unbelievable deals on electronics! Limited time offer\", \"Click here to claim your prize!\", \"You've been selected for a job interview.\", \"Dear Learner, You have successfully created your account on our website.\", \"Dear user, Your one time password is 24567.\", \"Congratullations Ansh, you have been shortlishted.\", \"Get rich quick!\", \"Discover 50 Full-Time Remote Jobs Now!\"]\n",
    "labels = [\"not spam\", \"spam\", \"not spam\", \"spam\", \"spam\", \"not spam\", \"spam\", \"spam\", \"not spam\", \"not spam\", \"not spam\", \"spam\", \"spam\", \"not spam\", \"not spam\", \"not spam\", \"spam\", \"not spam\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b54be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c2a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fd67b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Fit CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a859006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training my Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a82d8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "accuracy = model.score(X_test_counts, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e4eb94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['not spam']\n",
      "Prediction: ['spam']\n",
      "Prediction: ['spam']\n",
      "Prediction: ['not spam']\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "\n",
    "# Example (1)\n",
    "new_text = [\"Discover 50 Full-Time Remote Jobs Now!\"]\n",
    "new_text_counts = vectorizer.transform(new_text)\n",
    "prediction1 = model.predict(new_text_counts)\n",
    "print(f\"Prediction: {prediction1}\")\n",
    "\n",
    "\n",
    "# Example (2)\n",
    "new_text1 = [\"Congratulations, you got a new Iphone 15 pro, click to the link and get now! \"]\n",
    "new_text1_counts = vectorizer.transform(new_text1)\n",
    "prediction2 = model.predict(new_text1_counts)\n",
    "print(f\"Prediction: {prediction2}\")\n",
    "\n",
    "# Example (3)\n",
    "new_text2 = [\"Admissions closing soon for 2023. Limited seats left. Apply now.\"]\n",
    "new_text2_counts = vectorizer.transform(new_text2)\n",
    "prediction3 = model.predict(new_text2_counts)\n",
    "print(f\"Prediction: {prediction3}\")\n",
    "\n",
    "# Example (4)\n",
    "new_text3 = [\"Dear candidate, You are shortlisted.\"]\n",
    "new_text3_counts = vectorizer.transform(new_text3)\n",
    "prediction4 = model.predict(new_text3_counts)\n",
    "print(f\"Prediction: {prediction4}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5fae81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "# Provide the absolute path to the 'count_vectorizer.joblib' file\n",
    "vectorizer = load(\"C:\\\\Users\\\\asus\\\\Downloads\\email_spam_detection_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b548076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create and fit the TfidfVectorizer during training\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the email text during prediction\n",
    "#email_text_features = vectorizer.transform([email_text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6ff5c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a50a6a",
   "metadata": {},
   "source": [
    "### In conclusion, the Email Spam Detection (ML Model), developed as part of the Data Science Internship at Treue Technologies by me (Ansh Pandey), exhibits exceptional performance. With an accuracy rate of approximately 96%, this model effectively distinguishes between spam and legitimate emails. Its successful deployment and seamless integration into email systems make it a valuable tool for enhancing email communication security and efficiency. This project showcases the power of machine learning in addressing real-world challenges and is a testament to my (Ansh Pandey's) data science skills and dedication.\n",
    "\n",
    "Note : This model is trained with demo data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
